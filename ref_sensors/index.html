<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Ref sensors - 代理模拟器</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Ref sensors";
        var mkdocs_page_input_path = "ref_sensors.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> 代理模拟器
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">首页</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">代理模拟器</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Ref sensors</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/OpenHUTB/carla_doc/edit/master/docs/ref_sensors.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="_1"><a href="https://carla.readthedocs.io/en/latest/ref_sensors/">传感器参考</a></h1>
<ul>
<li><a href="#collision-detector"><strong>碰撞检测器</strong></a></li>
<li><a href="#depth-camera"><strong>深度相机</strong></a></li>
<li><a href="#gnss-sensor"><strong>全球导航卫星系统传感器</strong></a></li>
<li><a href="#imu-sensor"><strong>惯性测量单元传感器</strong></a></li>
<li><a href="#lane-invasion-detector"><strong>压线检测器</strong></a></li>
<li><a href="#lidar-sensor"><strong>激光雷达传感器</strong></a></li>
<li><a href="#obstacle-detector"><strong>障碍物检测器</strong></a></li>
<li><a href="#radar-sensor"><strong>雷达传感器</strong></a></li>
<li><a href="#rgb-camera"><strong>RGB相机</strong></a></li>
<li><a href="#rss-sensor"><strong>责任敏感安全传感器</strong></a></li>
<li><a href="#semantic-lidar-sensor"><strong>语义激光雷达传感器</strong></a></li>
<li><a href="#semantic-segmentation-camera"><strong>语义分割相机</strong></a></li>
<li><a href="#instance-segmentation-camera"><strong>实例分割相机</strong></a></li>
<li><a href="#dvs-camera"><strong>动态视觉传感器相机</strong></a></li>
<li><a href="#optical-flow-camera"><strong>光流相机</strong></a></li>
<li><a href="#fisheye-camera"><strong>鱼眼相机</strong></a></li>
<li><a href="#v2x-sensor"><strong>V2X 传感器</strong></a><ul>
<li><a href="#cooperative-awareness-message">协同感知</a></li>
<li><a href="#custom-v2x-message">自定义消息</a></li>
</ul>
</li>
</ul>
<div class="admonition 重要">
<p class="admonition-title">重要</p>
<p>所有传感器都使用虚幻引擎坐标系（<strong>x</strong> - <em>向前</em>，<strong>y</strong> - <em>向右</em>，<strong>z</strong> - <em>向上</em>），并返回本地空间中的坐标。使用任何可视化软件时，请注意其坐标系。许多反转 Y 轴，因此直接可视化传感器数据可能会导致镜像输出。传感器的具体实现请参考 <a href="../sensor/sensor_imp/">链接</a> 。</p>
</div>
<hr />
<h2 id="_2">碰撞检测器 <span id="collision-detector"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.other.collision</li>
<li><strong>输出：</strong> 每次碰撞的 <a href="../python_api/#carla.CollisionEvent">carla.CollisionEvent</a> 。</li>
</ul>
<p>每当其父参与者与世界上的某些物体发生碰撞时，该传感器都会记录一个事件。每个碰撞传感器每帧每次碰撞都会产生一个碰撞事件。通过与多个其他参与者的碰撞，可以在单个帧中产生多个碰撞事件。为了确保检测到与任何类型的对象的碰撞，服务器为建筑物或灌木丛等元素创建“假”参与者，以便可以检索语义标签来识别它。</p>
<p>碰撞检测器没有任何可配置的属性。</p>
<h4 id="_3">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>进行测量时的帧编号。</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>自回合开始以来测量的模拟时间（以秒为单位）。</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>测量时传感器在世界坐标中的位置和旋转。</td>
</tr>
<tr>
<td><code>actor</code></td>
<td><a href="../python_api#carlaactor">carla.Actor</a></td>
<td>测量碰撞的参与者（传感器的父级）。</td>
</tr>
<tr>
<td><code>other_actor</code></td>
<td><a href="../python_api#carlaactor">carla.Actor</a></td>
<td>与父级相撞的参与者。</td>
</tr>
<tr>
<td><code>normal_impulse</code></td>
<td><a href="../python_api#carlavector3d">carla.Vector3D</a></td>
<td>碰撞的正常脉冲结果。</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="_4">深度相机 <span id="depth-camera"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.camera.depth</li>
<li><strong>输出：</strong> 每步的图像 <a href="../python_api/#carla.Image">carla.Image</a> （除非<code>sensor_tick</code>另有说明）。</li>
</ul>
<p>相机提供场景的原始数据，编码每个像素到相机的距离（也称为<strong>深度缓冲区</strong>或 <strong>z 缓冲区</strong>）以创建元素的深度图。</p>
<p>该图像使用 RGB 颜色空间的 3 个通道（从低字节到高字节）对每个像素的深度值进行编码：<em>R -&gt; G -&gt; B</em>。以米为单位的实际距离可以通过以下方式解码：</p>
<div class="highlight"><pre><span></span><code>normalized = (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1)
in_meters = 1000 * normalized
</code></pre></div>
<p>然后，应使用<a href="../python_api/#carla.ColorConverter">carla.colorConverter</a>将输出<a href="../python_api/#carla.Image">carla.Image</a>保存到磁盘，该 <a href="../python_api/#carla.ColorConverter">carla.colorConverter</a> 会将存储在 RGB 通道中的距离转换为包含该距离的 <strong>[0,1]</strong> 浮点数，然后将其转换为灰度。<a href="../python_api/#carla.ColorConverter">carla.colorConverter</a> 中有两个选项可获取深度视图：<strong>Depth</strong> 和 <strong>Logaritmic depth</strong>。两者的精度都是毫米级的，但对数方法可以为更近的物体提供更好的结果。</p>
<div class="highlight"><pre><span></span><code><span class="o">...</span>
<span class="n">raw_image</span><span class="o">.</span><span class="n">save_to_disk</span><span class="p">(</span><span class="s2">&quot;path/to/save/converted/image&quot;</span><span class="p">,</span><span class="n">carla</span><span class="o">.</span><span class="n">Depth</span><span class="p">)</span>
</code></pre></div>
<p><img alt="ImageDepth" src="../img/ref_sensors_depth.jpg" /></p>
<h4 id="_5">相机基本属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>image_size_x</code></td>
<td>int</td>
<td>800</td>
<td>图像宽度（以像素为单位）。</td>
</tr>
<tr>
<td><code>image_size_y</code></td>
<td>int</td>
<td>600</td>
<td>图像高度（以像素为单位）。</td>
</tr>
<tr>
<td><code>fov</code></td>
<td>float</td>
<td>90.0</td>
<td>水平视野（以度为单位）。</td>
</tr>
<tr>
<td><code>sensor_tick</code></td>
<td>float</td>
<td>0.0</td>
<td>传感器捕获之间的模拟秒数（节拍）。</td>
</tr>
</tbody>
</table>
<h4 id="_6">相机镜头畸变属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>lens_circle_falloff</code></td>
<td>float</td>
<td>5.0</td>
<td>范围： [0.0, 10.0]</td>
</tr>
<tr>
<td><code>lens_circle_multiplier</code></td>
<td>float</td>
<td>0.0</td>
<td>范围： [0.0, 10.0]</td>
</tr>
<tr>
<td><code>lens_k</code></td>
<td>float</td>
<td>-1.0</td>
<td>范围： [-inf, inf]</td>
</tr>
<tr>
<td><code>lens_kcube</code></td>
<td>float</td>
<td>0.0</td>
<td>范围： [-inf, inf]</td>
</tr>
<tr>
<td><code>lens_x_size</code></td>
<td>float</td>
<td>0.08</td>
<td>范围： [0.0, 1.0]</td>
</tr>
<tr>
<td><code>lens_y_size</code></td>
<td>float</td>
<td>0.08</td>
<td>范围： [0.0, 1.0]</td>
</tr>
</tbody>
</table>
<h4 id="_7">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>进行测量时的帧编号。</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>自回合开始以来测量的模拟时间（以秒为单位）。</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>测量时传感器在世界坐标中的位置和旋转。</td>
</tr>
<tr>
<td><code>width</code></td>
<td>int</td>
<td>图像宽度（以像素为单位）。</td>
</tr>
<tr>
<td><code>height</code></td>
<td>int</td>
<td>图像高度（以像素为单位）。</td>
</tr>
<tr>
<td><code>fov</code></td>
<td>float</td>
<td>水平视野（以度为单位）。</td>
</tr>
<tr>
<td><code>raw_data</code></td>
<td>bytes</td>
<td>BGRA 32 位像素阵列。</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="_8">全球导航卫星系统传感器 <span id="gnss-sensor"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.other.gnss</li>
<li><strong>Output:</strong> 每一步的全球导航卫星系统的测量 <a href="../python_api/#carla.GnssMeasurement">carla.GNSSMeasurement</a> （<code>sensor_tick</code>另有说明）。</li>
</ul>
<p>报告其父对象的当前 <a href="https://www.gsa.europa.eu/european-gnss/what-gnss">gnss 位置</a> 。这是通过将度量位置添加到 OpenDRIVE 地图定义中定义的初始地理参考位置来计算的。</p>
<h4 id="_9">全球导航卫星系统属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>noise_alt_bias</code></td>
<td>float</td>
<td>0.0</td>
<td>海拔高度噪声模型中的平均参数。</td>
</tr>
<tr>
<td><code>noise_alt_stddev</code></td>
<td>float</td>
<td>0.0</td>
<td>海拔高度噪声模型中的标准偏差参数。</td>
</tr>
<tr>
<td><code>noise_lat_bias</code></td>
<td>float</td>
<td>0.0</td>
<td>纬度噪声模型中的平均参数。</td>
</tr>
<tr>
<td><code>noise_lat_stddev</code></td>
<td>float</td>
<td>0.0</td>
<td>纬度噪声模型中的标准偏差参数。</td>
</tr>
<tr>
<td><code>noise_lon_bias</code></td>
<td>float</td>
<td>0.0</td>
<td>经度噪声模型中的平均参数。</td>
</tr>
<tr>
<td><code>noise_lon_stddev</code></td>
<td>float</td>
<td>0.0</td>
<td>经度噪声模型中的标准偏差参数。</td>
</tr>
<tr>
<td><code>noise_seed</code></td>
<td>int</td>
<td>0</td>
<td>伪随机数生成器的初始化程序。</td>
</tr>
<tr>
<td><code>sensor_tick</code></td>
<td>float</td>
<td>0.0</td>
<td>传感器捕获之间的模拟秒数（节拍）。</td>
</tr>
</tbody>
</table>
<p><br></p>
<h4 id="_10">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>进行测量时的帧编号。</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>自回合开始以来测量的模拟时间（以秒为单位）。</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>测量时传感器在世界坐标中的位置和旋转。</td>
</tr>
<tr>
<td><code>latitude</code></td>
<td>double</td>
<td>参与者的纬度。</td>
</tr>
<tr>
<td><code>longitude</code></td>
<td>double</td>
<td>参与者的经度。</td>
</tr>
<tr>
<td><code>altitude</code></td>
<td>double</td>
<td>参与者的海拔高度。</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="_11"><a href="https://github.com/carla-simulator/carla/blob/dev/Unreal/CarlaUE4/Plugins/Carla/Source/Carla/Sensor/InertialMeasurementUnit.cpp">惯性测量单元传感器</a> <span id="imu-sensor"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.other.imu</li>
<li><strong>输出：</strong> 每一步的惯性测量单元测量值 <a href="../python_api/#carla.IMUMeasurement">carla.IMUMeasurement</a> （除非传感器节拍<code>sensor_tick</code>另有说明）。</li>
</ul>
<p>提供加速度计、陀螺仪和指南针将为父对象检索的测量值。数据是从对象的当前状态收集的。</p>
<h4 id="_12">惯性测量单元属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>noise_accel_stddev_x</code></td>
<td>float</td>
<td>0.0</td>
<td>加速度（X 轴）噪声模型中的标准偏差参数。</td>
</tr>
<tr>
<td><code>noise_accel_stddev_y</code></td>
<td>float</td>
<td>0.0</td>
<td>加速度（Y 轴）噪声模型中的标准偏差参数。</td>
</tr>
<tr>
<td><code>noise_accel_stddev_z</code></td>
<td>float</td>
<td>0.0</td>
<td>加速度（Z 轴）噪声模型中的标准偏差参数。</td>
</tr>
<tr>
<td><code>noise_gyro_bias_x</code></td>
<td>float</td>
<td>0.0</td>
<td>陀螺仪噪声模型中的平均参数（X 轴）。</td>
</tr>
<tr>
<td><code>noise_gyro_bias_y</code></td>
<td>float</td>
<td>0.0</td>
<td>陀螺仪噪声模型中的平均参数（Y 轴）。</td>
</tr>
<tr>
<td><code>noise_gyro_bias_z</code></td>
<td>float</td>
<td>0.0</td>
<td>陀螺仪噪声模型中的平均参数（Z 轴）。</td>
</tr>
<tr>
<td><code>noise_gyro_stddev_x</code></td>
<td>float</td>
<td>0.0</td>
<td>陀螺仪噪声模型中的标准偏差参数（X 轴）。</td>
</tr>
<tr>
<td><code>noise_gyro_stddev_y</code></td>
<td>float</td>
<td>0.0</td>
<td>陀螺仪噪声模型中的标准偏差参数（Y 轴）。</td>
</tr>
<tr>
<td><code>noise_gyro_stddev_z</code></td>
<td>float</td>
<td>0.0</td>
<td>陀螺仪噪声模型中的标准偏差参数（Z 轴）。</td>
</tr>
<tr>
<td><code>noise_seed</code></td>
<td>int</td>
<td>0</td>
<td>伪随机数生成器的初始化程序。</td>
</tr>
<tr>
<td><code>sensor_tick</code></td>
<td>float</td>
<td>0.0</td>
<td>传感器捕获之间的模拟秒数（节拍）。</td>
</tr>
</tbody>
</table>
<p><br></p>
<h4 id="_13">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>进行测量时的帧编号。</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>自回合开始以来测量的模拟时间（以秒为单位）。</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>测量时传感器在世界坐标中的位置和旋转。</td>
</tr>
<tr>
<td><a href="https://github.com/carla-simulator/carla/blob/dev/Unreal/CarlaUE4/Plugins/Carla/Source/Carla/Sensor/InertialMeasurementUnit.cpp#L102"><code>accelerometer</code></a></td>
<td><a href="../python_api#carlavector3d">carla.Vector3D</a></td>
<td>测量线性加速度（以 <code>m/s^2</code> 为单位）。</td>
</tr>
<tr>
<td><a href="https://github.com/carla-simulator/carla/blob/dev/Unreal/CarlaUE4/Plugins/Carla/Source/Carla/Sensor/InertialMeasurementUnit.cpp#L147"><code>gyroscope</code></a></td>
<td><a href="../python_api#carlavector3d">carla.Vector3D</a></td>
<td>测量角速度（以 <code>rad/sec</code> 为单位）。</td>
</tr>
<tr>
<td><a href="https://github.com/carla-simulator/carla/blob/dev/Unreal/CarlaUE4/Plugins/Carla/Source/Carla/Sensor/InertialMeasurementUnit.cpp#L167"><code>compass</code></a></td>
<td>float</td>
<td>以弧度为单位的方向。北是0弧度。</td>
</tr>
</tbody>
</table>
<ul>
<li>加速度计算方法：
<script type="math/tex; mode=display"> d_2 (i) = -2.0 \times [ { y_1 \over {h_1 \times h_2 } }  -  { y_2 \over { h_2 \times (h_1+h_2) } }  -  {y_0 \over { h_1 \times (h_1 + h_2) }} ] .</script>
</li>
</ul>
<p>其中，<script type="math/tex">h_1</script> 为当前时间增量，<script type="math/tex">h_2</script>为前一个时间增量。</p>
<div class="admonition 注意">
<p class="admonition-title">注意</p>
<p>对于指南针，北为 0 弧度。东为 <em>pi</em> /2 弧度，南为 <em>pi</em> 弧度，西为 3 <em>pi</em> /2 弧度。在 Carla 的全局坐标系中，北为 Y 轴减小的方向。东为 X 轴增加的方向。转换为度数的指南针值等于 <code>90 - 偏航</code>。 </p>
</div>
<hr />
<h2 id="_14">压线检测器 <span id="lane-invasion-detector"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.other.lane_invasion</li>
<li><strong>输出：</strong> 每次交叉路口的 <a href="../python_api/#carla.LaneInvasionEvent">carla.LaneInvasionEvent</a> 。</li>
</ul>
<p>每次其父级穿过车道标记时都会注册一个事件。传感器使用地图的 OpenDRIVE 描述提供的道路数据，通过考虑车轮之间的空间来确定主车辆是否正在侵入另一车道。然而，有一些事情需要考虑：</p>
<ul>
<li>OpenDRIVE 文件和地图之间的差异将导致不规则现象，例如在地图中不可见的交叉车道。</li>
<li>输出检索交叉车道标记列表：计算在 OpenDRIVE 中完成，并将四个车轮之间的整个空间视为一个整体。因此，可能有不止一条车道同时穿过。</li>
</ul>
<p>该传感器没有任何可配置属性。</p>
<div class="admonition 重要">
<p class="admonition-title">重要</p>
<p>该传感器完全在客户端工作。</p>
</div>
<h4 id="_15">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>进行测量时的帧编号。</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>自回合开始以来测量的模拟时间（以秒为单位）。</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>测量时传感器在世界坐标中的位置和旋转。</td>
</tr>
<tr>
<td><code>actor</code></td>
<td><a href="../python_api#carlaactor">carla.Actor</a></td>
<td>侵入另一车道的车辆（父参与者）。</td>
</tr>
<tr>
<td><code>crossed_lane_markings</code></td>
<td>list(<a href="../python_api#carlalanemarking">carla.LaneMarking</a>)</td>
<td>已穿越的车道标记列表。</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="_16">激光雷达传感器 <span id="lidar-sensor"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.lidar.ray_cast</li>
<li><strong>输出：</strong> 每一步 <a href="../python_api/#carla.LidarMeasurement">carla.LidarMeasurement</a> （除非<code>sensor_tick</code> 另有说明）。</li>
</ul>
<p>激光雷达测量包含一个包，其中包含在某个时间间隔内生成的所有点1/FPS。在此间隔期间，物理不会更新，因此测量中的所有点都反映场景的相同“静态图片”。
<code>points_per_channel_each_step = points_per_second / (FPS * channels)</code></p>
<p>此输出包含模拟点云，因此可以对其进行迭代以检索它们的列表 <a href="../python_api/#carla.Location"><code>carla.Location</code></a>：</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">location</span> <span class="ow">in</span> <span class="n">lidar_measurement</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">location</span><span class="p">)</span>
</code></pre></div>
<p>激光雷达测量的信息被编码为 4D 点。前三个是 xyz 坐标中的空间点，最后一个是行进过程中的强度损失。该强度通过以下公式计算：
<br>
<script type="math/tex; mode=display">
\frac{I}{I_0} = e^{-a \cdot d }
</script>
</p>
<p>其中，<code>a</code> 为衰减系数。这可能取决于传感器的波长和大气条件。可以使用激光雷达属性对其进行修改<code>atmosphere_attenuation_rate</code>。
<code>d</code> 为从击中点到传感器的距离。</p>
<p>为了获得更好的真实感，可以删除点云中的点。这是模拟外部扰动造成的损失的简单方法。这可以结合两个不同的来完成。</p>
<ul>
<li><strong>General drop-off</strong> — 随机掉落的分数比例。这是在跟踪之前完成的，这意味着不会计算被丢弃的点，从而提高性能。如果是<code>dropoff_general_rate = 0.5</code>，则扣掉一半的分数。</li>
<li><strong>Instensity-based drop-off</strong> — 对于检测到的每个点，根据计算的强度的概率执行额外的下降。该概率由两个参数确定。<code>dropoff_zero_intensity</code>是强度为零的点被丢弃的概率。<code>dropoff_intensity_limit</code>是阈值强度，超过该阈值将不会掉落任何分数。范围内的点被丢弃的概率是基于这两个参数的线性比例。</li>
</ul>
<p>此外，该<code>noise_stddev</code>属性还使噪声模型能够模拟现实传感器中出现的意外偏差。对于正值，每个点都会沿着激光射线的矢量随机扰动。结果是激光雷达传感器具有完美的角度定位，但距离测量存在噪音。</p>
<p>可以调整激光雷达的旋转以覆盖每个模拟步骤的特定角度（使用 <a href="../adv_synchrony_timestep/">固定的时间步长</a> ）。例如，每步旋转一次（整圈输出，如下图），旋转频率和模拟的 FPS 应该相等。 <br> <strong>1.</strong> 设置传感器的频率 <code>sensors_bp['lidar'][0].set_attribute('rotation_frequency','10')</code>. <br> <strong>2.</strong> 使用 <code>python3 config.py --fps=10</code> 运行模拟。</p>
<p><img alt="LidarPointCloud" src="../img/lidar_point_cloud.jpg" /></p>
<h4 id="_17">激光雷达属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>channels</code></td>
<td>int</td>
<td>32</td>
<td>激光器数量。</td>
</tr>
<tr>
<td><code>range</code></td>
<td>float</td>
<td>10.0</td>
<td>测量/光线投射的最大距离以米为单位（Carla 0.9.6 或更低版本为厘米）。</td>
</tr>
<tr>
<td><code>points_per_second</code></td>
<td>int</td>
<td>56000</td>
<td>所有激光器每秒生成的点。</td>
</tr>
<tr>
<td><code>rotation_frequency</code></td>
<td>float</td>
<td>10.0</td>
<td>激光雷达旋转频率。</td>
</tr>
<tr>
<td><code>upper_fov</code></td>
<td>float</td>
<td>10.0</td>
<td>最高激光的角度（以度为单位）。</td>
</tr>
<tr>
<td><code>lower_fov</code></td>
<td>float</td>
<td>-30.0</td>
<td>最低激光的角度（以度为单位）。</td>
</tr>
<tr>
<td><code>horizontal_fov</code></td>
<td>float</td>
<td>360.0</td>
<td>水平视野（以度为单位），0 - 360。</td>
</tr>
<tr>
<td><code>atmosphere_attenuation_rate</code></td>
<td>float</td>
<td>0.004</td>
<td>测量每米激光雷达强度损失的系数。检查上面的强度计算。</td>
</tr>
<tr>
<td><code>dropoff_general_rate</code></td>
<td>float</td>
<td>0.45</td>
<td>随机丢弃的点的一般比例。</td>
</tr>
<tr>
<td><code>dropoff_intensity_limit</code></td>
<td>float</td>
<td>0.8</td>
<td>对于基于强度的下降，高于该阈值的强度值没有任何点被下降。</td>
</tr>
<tr>
<td><code>dropoff_zero_intensity</code></td>
<td>float</td>
<td>0.4</td>
<td>对于基于强度的下降，每个强度为零的点被下降的概率。</td>
</tr>
<tr>
<td><code>sensor_tick</code></td>
<td>float</td>
<td>0.0</td>
<td>传感器捕获之间的模拟秒数（节拍）。</td>
</tr>
<tr>
<td><code>noise_stddev</code></td>
<td>float</td>
<td>0.0</td>
<td>噪声模型的标准偏差，用于干扰沿其光线投射矢量的每个点。</td>
</tr>
</tbody>
</table>
<h4 id="_18">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>进行测量时的帧编号。</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>自回合开始以来测量的模拟时间（以秒为单位）。</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>测量时传感器在世界坐标中的位置和旋转。</td>
</tr>
<tr>
<td><code>horizontal_angle</code></td>
<td>float</td>
<td>当前帧中激光雷达的 XY 平面中的角度（弧度）。</td>
</tr>
<tr>
<td><code>channels</code></td>
<td>int</td>
<td>激光雷达的通道（激光器）数量。</td>
</tr>
<tr>
<td><code>get_point_count(channel)</code></td>
<td>int</td>
<td>每个通道捕获此帧的点数。</td>
</tr>
<tr>
<td><code>raw_data</code></td>
<td>bytes</td>
<td>32 位浮点数组（每个点的 XYZI）。</td>
</tr>
</tbody>
</table>
<p><br></p>
<h2 id="_19">障碍物检测器 <span id="obstacle-detector"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.other.obstacle</li>
<li><strong>输出：</strong> 每个障碍物的 <a href="../python_api/#carla.ObstacleDetectionEvent">carla.ObstacleDetectionEvent</a> （除非<code>sensor_tick</code>另有说明）。</li>
</ul>
<p>每当父级参与者前方有障碍时，都会注册一个事件。为了预测障碍物，传感器在母车前方创建一个胶囊形状，并用它来检查碰撞。为了确保检测到与任何类型的对象的碰撞，服务器为建筑物或灌木丛等元素创建“假”参与者，以便可以检索语义标签来识别它。</p>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>distance</code></td>
<td>float</td>
<td>5</td>
<td>轨迹距离。</td>
</tr>
<tr>
<td><code>hit_radius</code></td>
<td>float</td>
<td>0.5</td>
<td>轨迹的半径。</td>
</tr>
<tr>
<td><code>only_dynamics</code></td>
<td>bool</td>
<td>False</td>
<td>如果为 true，则轨迹将仅考虑动态对象。</td>
</tr>
<tr>
<td><code>debug_linetrace</code></td>
<td>bool</td>
<td>False</td>
<td>如果为 true，则轨迹将可见。</td>
</tr>
<tr>
<td><code>sensor_tick</code></td>
<td>float</td>
<td>0.0</td>
<td>传感器捕获之间的模拟秒数（节拍）。</td>
</tr>
</tbody>
</table>
<p><br></p>
<h4 id="_20">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>进行测量时的帧编号。</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>自回车开始以来测量的模拟时间（以秒为单位）。</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>测量时传感器在世界坐标中的位置和旋转。</td>
</tr>
<tr>
<td><code>actor</code></td>
<td><a href="../python_api#carlaactor">carla.Actor</a></td>
<td>检测到障碍物的参与者（父级参与者）。</td>
</tr>
<tr>
<td><code>other_actor</code></td>
<td><a href="../python_api#carlaactor">carla.Actor</a></td>
<td>参与者被检测为障碍物。</td>
</tr>
<tr>
<td><code>distance</code></td>
<td>float</td>
<td>从参与者 <code>actor</code> 到其他参与者 <code>other_actor</code> 的距离。</td>
</tr>
</tbody>
</table>
<p><br></p>
<h2 id="_21">雷达传感器 <span id="radar-sensor"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.other.radar</li>
<li><strong>输出：</strong> 每一步 <a href="../python_api/#carla.RadarMeasurement">carla.RadarMeasurement</a> （除非<code>sensor_tick</code>另有说明）。</li>
</ul>
<p>传感器创建一个圆锥视图，该视图被转换为视野中的元素及其相对于传感器的速度的二维点图。这可用于塑造元素并评估它们的运动和方向。由于使用极坐标，这些点将集中在视图中心周围。</p>
<p>测量的点作为<a href="../python_api/#carla.RadarDetection">carla.RadarDetection</a>数组包含在<a href="../python_api/#carla.RadarMeasurement">carla.RadarMeasurement</a>中，该数组指定它们的极坐标、距离和速度。雷达传感器提供的原始数据可以轻松转换为 <strong>numpy</strong> 可管理的格式：
<div class="highlight"><pre><span></span><code><span class="c1"># 为了获得 numpy [[vel, azimuth, altitude, depth],...[,,,]]:</span>
<span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">radar_data</span><span class="o">.</span><span class="n">raw_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;f4&#39;</span><span class="p">))</span>
<span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">radar_data</span><span class="p">),</span> <span class="mi">4</span><span class="p">))</span>
</code></pre></div></p>
<p>提供的脚本<code>manual_control.py</code>使用此传感器来显示正在检测的点，并在静态时将其绘制为白色，在向物体移动时将其绘制为红色，在远离物体时将其绘制为蓝色：</p>
<p><img alt="ImageRadar" src="../img/ref_sensors_radar.jpg" /></p>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>horizontal_fov</code></td>
<td>float</td>
<td>30.0</td>
<td>水平视野（以度为单位）。</td>
</tr>
<tr>
<td><code>points_per_second</code></td>
<td>int</td>
<td>1500</td>
<td>所有激光器每秒生成的点。</td>
</tr>
<tr>
<td><code>range</code></td>
<td>float</td>
<td>100</td>
<td>测量/光线投射的最大距离（以米为单位）。</td>
</tr>
<tr>
<td><code>sensor_tick</code></td>
<td>float</td>
<td>0.0</td>
<td>传感器捕获之间的模拟秒数（节拍）。</td>
</tr>
<tr>
<td><code>vertical_fov</code></td>
<td>float</td>
<td>30.0</td>
<td>垂直视野（以度为单位）。</td>
</tr>
</tbody>
</table>
<p><br></p>
<h4 id="_22">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>raw_data</code></td>
<td><a href="../python_api#carlaradardetection">carla.RadarDetection</a></td>
<td>检测到的点列表。</td>
</tr>
</tbody>
</table>
<p><br></p>
<table>
<thead>
<tr>
<th>RadarDetection 属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>altitude</code></td>
<td>float</td>
<td>以弧度表示的高度角。</td>
</tr>
<tr>
<td><code>azimuth</code></td>
<td>float</td>
<td>方位角（以弧度表示）。</td>
</tr>
<tr>
<td><code>depth</code></td>
<td>float</td>
<td>距离以米为单位。</td>
</tr>
<tr>
<td><code>velocity</code></td>
<td>float</td>
<td>朝向传感器的速度。</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="rgb">RGB 相机 <span id="rgb-camera"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.camera.rgb</li>
<li><strong>输出：</strong> 每一步 <a href="../python_api/#carla.Image">carla.Image</a> （除非<code>sensor_tick</code>另有说明）。</li>
</ul>
<p>“RGB”相机充当捕获场景图像的常规相机。
<a href="../python_api/#carla.ColorConverter">carla.colorConverter</a></p>
<p>如果 <code>enable_postprocess_effects</code> 启用，为了真实感，一组后处理效果将应用于图像：</p>
<ul>
<li><strong>Vignette:</strong> 使屏幕边框变暗。</li>
<li><strong>Grain jitter:</strong> 为渲染添加一些噪点。</li>
<li><strong>Bloom:</strong> 强烈的光线会灼烧它们周围的区域。</li>
<li><strong>Auto exposure:</strong> 修改图像伽玛以模拟眼睛对较暗或较亮区域的适应。</li>
<li><strong>Lens flares:</strong> 模拟明亮物体在镜头上的反射。</li>
<li><strong>Depth of field:</strong> 模糊靠近或远离相机的物体。</li>
</ul>
<p><code>sensor_tick</code>告诉我们希望传感器捕获数据的速度有多快。值为 1.5 意味着我们希望传感器每半秒捕获一次数据。默认情况下，值 0.0 表示尽可能快。</p>
<p><img alt="ImageRGB" src="../img/ref_sensors_rgb.jpg" /></p>
<p>其实现原理参考 <a href="../sensor/camera_analysis/">视觉传感器器系列实现原理分析</a> 。</p>
<h4 id="_23">相机基本属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>bloom_intensity</code></td>
<td>float</td>
<td>0.675</td>
<td>光晕后处理效果的强度，<code>0.0</code>用于禁用它。</td>
</tr>
<tr>
<td><code>fov</code></td>
<td>float</td>
<td>90.0</td>
<td>水平视野（以度为单位）。</td>
</tr>
<tr>
<td><code>fstop</code></td>
<td>float</td>
<td>1.4</td>
<td>相机镜头的打开。典型镜头的光圈<code>1/fstop</code>为 f/1.2（更大的光圈）。较大的数字将减少景深效果。</td>
</tr>
<tr>
<td><code>image_size_x</code></td>
<td>int</td>
<td>800</td>
<td>图像宽度（以像素为单位）。</td>
</tr>
<tr>
<td><code>image_size_y</code></td>
<td>int</td>
<td>600</td>
<td>图像高度（以像素为单位）。</td>
</tr>
<tr>
<td><code>iso</code></td>
<td>float</td>
<td>100.0</td>
<td>相机传感器的灵敏度。</td>
</tr>
<tr>
<td><code>gamma</code></td>
<td>float</td>
<td>2.2</td>
<td>相机的目标伽玛值。</td>
</tr>
<tr>
<td><code>lens_flare_intensity</code></td>
<td>float</td>
<td>0.1</td>
<td>镜头眩光后处理效果的强度，<code>0.0</code>用于禁用它。</td>
</tr>
<tr>
<td><code>sensor_tick</code></td>
<td>float</td>
<td>0.0</td>
<td>传感器捕获之间的模拟秒数（节拍）。</td>
</tr>
<tr>
<td><code>shutter_speed</code></td>
<td>float</td>
<td>200.0</td>
<td>相机快门速度，以秒为单位 (1.0/s)。</td>
</tr>
</tbody>
</table>
<h4 id="_24">相机镜头畸变属性</h4>
<p><br></p>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>lens_circle_falloff</code></td>
<td>float</td>
<td>5.0</td>
<td>范围： [0.0, 10.0]</td>
</tr>
<tr>
<td><code>lens_circle_multiplier</code></td>
<td>float</td>
<td>0.0</td>
<td>范围： [0.0, 10.0]</td>
</tr>
<tr>
<td><code>lens_k</code></td>
<td>float</td>
<td>-1.0</td>
<td>范围： [-inf, inf]</td>
</tr>
<tr>
<td><code>lens_kcube</code></td>
<td>float</td>
<td>0.0</td>
<td>范围： [-inf, inf]</td>
</tr>
<tr>
<td><code>lens_x_size</code></td>
<td>float</td>
<td>0.08</td>
<td>范围： [0.0, 1.0]</td>
</tr>
<tr>
<td><code>lens_y_size</code></td>
<td>float</td>
<td>0.08</td>
<td>范围： [0.0, 1.0]</td>
</tr>
</tbody>
</table>
<h4 id="_25">高级相机属性</h4>
<p>由于这些效果是由虚幻引擎提供的，请务必检查他们的文档：</p>
<ul>
<li><a href="https://docs.unrealengine.com/en-US/Engine/Rendering/PostProcessEffects/AutomaticExposure/index.html">自动曝光</a></li>
<li><a href="https://docs.unrealengine.com/en-US/Engine/Rendering/PostProcessEffects/DepthOfField/CinematicDOFMethods/index.html">影视级景深方案</a></li>
<li><a href="https://docs.unrealengine.com/en-US/Engine/Rendering/PostProcessEffects/ColorGrading/index.html">颜色分级和电影色调映射器</a></li>
</ul>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>min_fstop</code></td>
<td>float</td>
<td>1.2</td>
<td>最大光圈。</td>
</tr>
<tr>
<td><code>blade_count</code></td>
<td>int</td>
<td>5</td>
<td>构成隔膜机构的叶片数量。</td>
</tr>
<tr>
<td><code>exposure_mode</code></td>
<td>str</td>
<td><code>histogram</code></td>
<td>可以是 <code>manual</code> 或or <code>histogram</code>。更多内容请参见<a href="https://docs.unrealengine.com/en-US/Engine/Rendering/PostProcessEffects/AutomaticExposure/index.html">UE4 文档</a>。</td>
</tr>
<tr>
<td><code>exposure_compensation</code></td>
<td>float</td>
<td><strong>Linux:</strong> +0.75<br><strong>Windows:</strong> 0.0</td>
<td>曝光的对数调整。0：无调整，-1：2 倍更暗，-2：4 更暗，1：2 倍更亮，2：4 倍更亮。</td>
</tr>
<tr>
<td><code>exposure_min_bright</code></td>
<td>float</td>
<td>10.0</td>
<td>在<code>exposure_mode: "histogram"</code>。自动曝光的最低亮度。眼睛能适应的最低限度。必须大于 0 且小于或等于<code>exposure_max_bright</code>。</td>
</tr>
<tr>
<td><code>exposure_max_bright</code></td>
<td>float</td>
<td>12.0</td>
<td>在`exposure_mode: "histogram"`中。自动曝光的最大亮度。眼睛能适应的最高限度。必须大于 0 且大于或等于 `exposure_min_bright`。</td>
</tr>
<tr>
<td><code>exposure_speed_up</code></td>
<td>float</td>
<td>3.0</td>
<td>在 <code>exposure_mode: "histogram"</code>。。从黑暗环境到明亮环境的适应速度。</td>
</tr>
<tr>
<td><code>exposure_speed_down</code></td>
<td>float</td>
<td>1.0</td>
<td>在 <code>exposure_mode: "histogram"</code>。从明亮环境到黑暗环境的适应速度。</td>
</tr>
<tr>
<td><code>calibration_constant</code></td>
<td>float</td>
<td>16.0</td>
<td>18% 反照率的校准常数。</td>
</tr>
<tr>
<td><code>focal_distance</code></td>
<td>float</td>
<td>1000.0</td>
<td>景深效果应清晰的距离。以厘米（虚幻引擎单位）为单位测量。</td>
</tr>
<tr>
<td><code>blur_amount</code></td>
<td>float</td>
<td>1.0</td>
<td>运动模糊的强度/强度。</td>
</tr>
<tr>
<td><code>blur_radius</code></td>
<td>float</td>
<td>0.0</td>
<td>1080p 分辨率下的半径（以像素为单位），根据距相机的距离模拟大气散射。</td>
</tr>
<tr>
<td><code>motion_blur_intensity</code></td>
<td>float</td>
<td>0.45</td>
<td>运动模糊的强度 [0,1]。</td>
</tr>
<tr>
<td><code>motion_blur_max_distortion</code></td>
<td>float</td>
<td>0.35</td>
<td>运动模糊引起的最大失真。屏幕宽度的百分比。</td>
</tr>
<tr>
<td><code>motion_blur_min_object_screen_size</code></td>
<td>float</td>
<td>0.1</td>
<td>对于运动模糊，对象必须具有屏幕宽度的百分比，较低的值意味着较少的绘制调用。</td>
</tr>
<tr>
<td><code>slope</code></td>
<td>float</td>
<td>0.88</td>
<td>色调映射器 S 曲线的陡度。值越大，斜率越陡（越暗）[0.0, 1.0]。</td>
</tr>
<tr>
<td><code>toe</code></td>
<td>float</td>
<td>0.55</td>
<td>调整色调映射器中的深色 [0.0, 1.0]。</td>
</tr>
<tr>
<td><code>shoulder</code></td>
<td>float</td>
<td>0.26</td>
<td>调整色调映射器中的明亮颜色 [0.0, 1.0]。</td>
</tr>
<tr>
<td><code>black_clip</code></td>
<td>float</td>
<td>0.0</td>
<td>不应调整此值。设置交叉发生和黑色色调开始切断其值的位置 [0.0, 1.0]。</td>
</tr>
<tr>
<td><code>white_clip</code></td>
<td>float</td>
<td>0.04</td>
<td>设置交叉发生的位置，并且白色色调开始切断其值。大多数情况下会有细微的变化 [0.0, 1.0]。</td>
</tr>
<tr>
<td><code>temp</code></td>
<td>float</td>
<td>6500.0</td>
<td>白平衡与场景中光线的温度有关。<strong>白光</strong>：当与光温匹配时。<strong>暖光</strong>：当高于场景中的光线时，呈淡黄色。<strong>冷光</strong>：低于光线时。蓝色。</td>
</tr>
<tr>
<td><code>tint</code></td>
<td>float</td>
<td>0.0</td>
<td>白平衡温度色调。调整青色和洋红色的颜色范围。这应该与白平衡温度属性一起使用以获得准确的颜色。在某些光温下，颜色可能看起来更黄或更蓝。这可用于平衡最终的颜色，使其看起来更自然。</td>
</tr>
<tr>
<td><code>chromatic_aberration_intensity</code></td>
<td>float</td>
<td>0.0</td>
<td>用于控制色彩偏移的缩放因子，在屏幕边框上更明显。</td>
</tr>
<tr>
<td><code>chromatic_aberration_offset</code></td>
<td>float</td>
<td>0.0</td>
<td>到发生效果的图像中心的正则化距离。</td>
</tr>
<tr>
<td><code>enable_postprocess_effects</code></td>
<td>bool</td>
<td>True</td>
<td>后处理效果激活。</td>
</tr>
</tbody>
</table>
<p><br></p>
<h4 id="_26">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>进行测量时的帧编号。</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>自回合开始以来测量的模拟时间（以秒为单位）。</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>测量时传感器在世界坐标中的位置和旋转。</td>
</tr>
<tr>
<td><code>width</code></td>
<td>int</td>
<td>图像宽度（以像素为单位）。</td>
</tr>
<tr>
<td><code>height</code></td>
<td>int</td>
<td>图像高度（以像素为单位）。</td>
</tr>
<tr>
<td><code>fov</code></td>
<td>float</td>
<td>水平视野（以度为单位）。</td>
</tr>
<tr>
<td><code>raw_data</code></td>
<td>bytes</td>
<td>BGRA 32 位像素阵列。</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="_27">责任敏感安全传感器 <span id="rss-sensor"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.other.rss</li>
<li><strong>输出：</strong> 每一步 <a href="../python_api/#carla.RssResponse">carla.RssResponse</a> （除非<code>sensor_tick</code>另有说明）。</li>
</ul>
<div class="admonition 重要">
<p class="admonition-title">重要</p>
<p>强烈建议在阅读本文之前先阅读具体的 <a href="../adv_rss/">任敏感安全文档</a> （自 Carla 0.9.15 起已被弃用）。</p>
</div>
<p>该传感器集成了 Carla 中的 <a href="https://github.com/intel/ad-rss-lib">责任敏感安全 C++ 库</a> 。它在 Carla 中默认被禁用，并且必须显式构建才能使用。</p>
<p>责任敏感安全传感器计算车辆的责任敏感安全状态并检索当前的责任敏感安全响应作为传感器数据。<a href="../python_api/#carla.RssRestrictor">carla.RssRestrictor</a>将使用此数据来调整<a href="../python_api/#carla.VehicleControl">carla.VehicleControl</a> ，然后再将其应用于车辆。</p>
<p>这些控制器可以通过<em>自动驾驶</em>堆栈或用户输入生成。例如，下面有一段来自 <a href="https://github.com/OpenHUTB/carla_doc/blob/master/src/examples/manual_control_rss.py"><code>PythonAPI/examples/rss/manual_control_rss.py</code></a> 的代码片段，其中在必要时使用责任敏感安全修改用户输入。
<br>
<strong>1.</strong> 检查 <strong>RssSensor</strong> 是否生成包含限制的有效响应。<br>
<strong>2.</strong> 收集车辆的当前动态和车辆物理特性。<br>
<strong>3.</strong> 使用 RssSensor 的响应以及车辆当前的动态和物理特性对车辆控制施加限制。</p>
<div class="highlight"><pre><span></span><code><span class="n">rss_proper_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_world</span><span class="o">.</span><span class="n">rss_sensor</span><span class="o">.</span><span class="n">proper_response</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_world</span><span class="o">.</span><span class="n">rss_sensor</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_world</span><span class="o">.</span><span class="n">rss_sensor</span><span class="o">.</span><span class="n">response_valid</span> <span class="k">else</span> <span class="kc">None</span>
<span class="k">if</span> <span class="n">rss_proper_response</span><span class="p">:</span>
<span class="o">...</span>
        <span class="n">vehicle_control</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_restrictor</span><span class="o">.</span><span class="n">restrict_vehicle_control</span><span class="p">(</span>
            <span class="n">vehicle_control</span><span class="p">,</span> <span class="n">rss_proper_response</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_world</span><span class="o">.</span><span class="n">rss_sensor</span><span class="o">.</span><span class="n">ego_dynamics_on_route</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vehicle_physics</span><span class="p">)</span>
</code></pre></div>
<h4 id="carlarsssensor">carla.RssSensor 类</h4>
<p>该传感器的蓝图没有可修改的属性。但是，它实例化的 <a href="../python_api/#carla.RssSensor">carla.RssSensor</a> 对象具有 Python API 参考中详细介绍的属性和方法。以下是它们的摘要。</p>
<table>
<thead>
<tr>
<th><a href="../python_api#carlarsssensor">carla.RssSensor 变量</a></th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ego_vehicle_dynamics</code></td>
<td><a href="https://intel.github.io/ad-rss-lib/ad_rss/Appendix-ParameterDiscussion/">ad.rss.world.RssDynamics</a></td>
<td>应用于自我车辆的责任敏感安全参数</td>
</tr>
<tr>
<td><code>other_vehicle_dynamics</code></td>
<td><a href="https://intel.github.io/ad-rss-lib/ad_rss/Appendix-ParameterDiscussion/">ad.rss.world.RssDynamics</a></td>
<td>适用于其他车辆的责任敏感安全参数</td>
</tr>
<tr>
<td><code>pedestrian_dynamics</code></td>
<td><a href="https://intel.github.io/ad-rss-lib/ad_rss/Appendix-ParameterDiscussion/">ad.rss.world.RssDynamics</a></td>
<td>适用于行人的责任敏感安全参数</td>
</tr>
<tr>
<td><code>road_boundaries_mode</code></td>
<td><a href="../python_api#carlarssroadboundariesmode">carla.RssRoadBoundariesMode</a></td>
<td>启用/禁用 <a href="https://intel.github.io/ad-rss-lib/ad_rss_map_integration/HandleRoadBoundaries">留在道路上</a> 功能。默认为<strong>关闭</strong>。</td>
</tr>
</tbody>
</table>
<p><br></p>
<div class="highlight"><pre><span></span><code><span class="c1"># rss_sensor.py 代码片段</span>
<span class="c1"># 当监听到一个新的carla.RssResponse时，更新 carla.RssSensor</span>
<span class="k">def</span> <span class="nf">_on_rss_response</span><span class="p">(</span><span class="n">weak_self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
<span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">timestamp</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">timestamp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">response_valid</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">response_valid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proper_response</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">proper_response</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ego_dynamics_on_route</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">ego_dynamics_on_route</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rss_state_snapshot</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">rss_state_snapshot</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">situation_snapshot</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">situation_snapshot</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">world_model</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">world_model</span>
</code></pre></div>
<div class="admonition 警告">
<p class="admonition-title">警告</p>
<p>该传感器在客户端完全工作。服务器中没有蓝图。对属性的更改将在调用<em>listen()</em> <strong>后</strong> 生效。</p>
</div>
<p>此类中可用的方法与车辆的路线有关。责任敏感安全计算始终基于本车通过道路网络的路线。</p>
<p>传感器允许通过提供一些关键点来控制所考虑的路线，这些关键点可能是<a href="../python_api/#carla.Transform">carla.Transform</a>中的 <a href="../python_api/#carla.Waypoint">carla.Waypoint</a>。最好在交叉点之后选择这些点，以强制路线采取所需的转弯。</p>
<table>
<thead>
<tr>
<th><a href="../python_api#carlarsssensor">carla.RssSensor 方法</a></th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>routing_targets</code></td>
<td>获取用于路由的当前路由目标列表。</td>
</tr>
<tr>
<td><code>append_routing_target</code></td>
<td>将附加位置附加到当前路由目标。</td>
</tr>
<tr>
<td><code>reset_routing_targets</code></td>
<td>删除附加的路由目标。</td>
</tr>
<tr>
<td><code>drop_route</code></td>
<td>放弃当前路由并创建一条新路由。</td>
</tr>
<tr>
<td><code>register_actor_constellation_callback</code></td>
<td>注册回调来自定义计算。</td>
</tr>
<tr>
<td><code>set_log_level</code></td>
<td>设置日志级别。</td>
</tr>
<tr>
<td><code>set_map_log_level</code></td>
<td>设置用于地图相关日志的日志级别。</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre><span></span><code><span class="c1"># 更新当前路线</span>
<span class="bp">self</span><span class="o">.</span><span class="n">sensor</span><span class="o">.</span><span class="n">reset_routing_targets</span><span class="p">()</span>
<span class="k">if</span> <span class="n">routing_targets</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">routing_targets</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sensor</span><span class="o">.</span><span class="n">append_routing_target</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
</code></pre></div>
<div class="admonition 笔记">
<p class="admonition-title">笔记</p>
<p>如果未定义路由目标，则会创建随机路由。</p>
</div>
<h4 id="_28">输出属性</h4>
<table>
<thead>
<tr>
<th><a href="../python_api#carlarssresponse">carla.RssResponse 属性</a></th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>response_valid</code></td>
<td>bool</td>
<td>响应数据的有效性。</td>
</tr>
<tr>
<td><code>proper_response</code></td>
<td><a href="https://intel.github.io/ad-rss-lib/doxygen/ad_rss/structad_1_1rss_1_1state_1_1ProperResponse.html">ad.rss.state.ProperResponse</a></td>
<td>责任敏感安全为车辆计算的正确响应，包括加速限制。</td>
</tr>
<tr>
<td><code>rss_state_snapshot</code></td>
<td><a href="https://intel.github.io/ad-rss-lib/doxygen/ad_rss/structad_1_1rss_1_1state_1_1RssStateSnapshot.html">ad.rss.state.RssStateSnapshot</a></td>
<td>责任敏感安全状态为当前时间点。这是责任敏感安全计算的详细的单独输出。</td>
</tr>
<tr>
<td><code>situation_snapshot</code></td>
<td><a href="https://intel.github.io/ad-rss-lib/doxygen/ad_rss/structad_1_1rss_1_1situation_1_1SituationSnapshot.html">ad.rss.situation.SituationSnapshot</a></td>
<td>当前时间点的责任敏感安全情况。这是用于 责任敏感安全 计算的经过处理的输入数据。</td>
</tr>
<tr>
<td><code>world_model</code></td>
<td><a href="https://intel.github.io/ad-rss-lib/doxygen/ad_rss/structad_1_1rss_1_1world_1_1WorldModel.html">ad.rss.world.WorldModel</a></td>
<td>当前时间点的 责任敏感安全 世界模型。这是 责任敏感安全 计算的输入数据。</td>
</tr>
<tr>
<td><code>ego_dynamics_on_route</code></td>
<td><a href="../python_api#carlarssegodynamicsonroute">carla.RssEgoDynamicsOnRoute</a></td>
<td>关于路线的当前自我车辆动态。</td>
</tr>
</tbody>
</table>
<p>如果注册了 actor_constellation_callback，则会触发以下调用：</p>
<ol>
<li>默认计算 (<code>actor_constellation_data.other_actor=None</code>)</li>
<li>每个参与者的计算</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="c1"># rss_sensor.py 代码片段</span>
<span class="c1"># 注册该函数为 actor_constellation_callback</span>
<span class="k">def</span> <span class="nf">_on_actor_constellation_request</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actor_constellation_data</span><span class="p">):</span>
    <span class="n">actor_constellation_result</span> <span class="o">=</span> <span class="n">carla</span><span class="o">.</span><span class="n">RssActorConstellationResult</span><span class="p">()</span>
    <span class="n">actor_constellation_result</span><span class="o">.</span><span class="n">rss_calculation_mode</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">rss</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">RssMode</span><span class="o">.</span><span class="n">NotRelevant</span>
    <span class="n">actor_constellation_result</span><span class="o">.</span><span class="n">restrict_speed_limit_mode</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">rss</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">RssSceneCreation</span><span class="o">.</span><span class="n">RestrictSpeedLimitMode</span><span class="o">.</span><span class="n">IncreasedSpeedLimit10</span>
    <span class="n">actor_constellation_result</span><span class="o">.</span><span class="n">ego_vehicle_dynamics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_vehicle_parameters</span>
    <span class="n">actor_constellation_result</span><span class="o">.</span><span class="n">actor_object_type</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">rss</span><span class="o">.</span><span class="n">world</span><span class="o">.</span><span class="n">ObjectType</span><span class="o">.</span><span class="n">Invalid</span>
    <span class="n">actor_constellation_result</span><span class="o">.</span><span class="n">actor_dynamics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_vehicle_parameters</span>

    <span class="n">actor_id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">actor_type_id</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span>
    <span class="k">if</span> <span class="n">actor_constellation_data</span><span class="o">.</span><span class="n">other_actor</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># 为特定的参与者定制 actor_constellation_result</span>
        <span class="o">...</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># 默认</span>
        <span class="o">...</span>
    <span class="k">return</span> <span class="n">actor_constellation_result</span>
</code></pre></div>
<hr />
<h2 id="_29">语义激光雷达传感器 <span id="semantic-lidar-sensor"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.lidar.ray_cast_semantic</li>
<li><strong>输出：</strong> 每步 <a href="../python_api/#carla.SemanticLidarMeasurement">carla.SemanticLidarMeasurement</a> （除非<code>sensor_tick</code>另有说明）。</li>
</ul>
<p>该传感器模拟使用射线投射实现的旋转激光雷达，公开有关射线投射命中的所有信息。它的行为与 <a href="#lidar-sensor">激光雷达传感器</a> 非常相似，但它们之间有两个主要区别。</p>
<ul>
<li>语义激光雷达检索到的原始数据每个点包含更多数据。<ul>
<li>该点的坐标（与普通激光雷达一样）。</li>
<li>入射角与表面法线之间的余弦值。</li>
<li>实例和语义基础事实。基本上是 Carla 对象命中的索引及其语义标签。</li>
</ul>
</li>
<li>语义激光雷达既不包含强度、衰减也不包含噪声模型属性。</li>
</ul>
<p>这些点是通过为垂直 FOV 中分布的每个通道添加激光来计算的。旋转是通过计算激光雷达在一帧中旋转的水平角度来模拟的。点云是通过在每个步骤中对每个激光进行光线投射来计算的。
<div class="highlight"><pre><span></span><code><span class="nv">points_per_channel_each_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>points_per_second<span class="w"> </span>/<span class="w"> </span><span class="o">(</span>FPS<span class="w"> </span>*<span class="w"> </span>channels<span class="o">)</span>
</code></pre></div></p>
<p>激光雷达测量包含一个包，其中包含在某个时间 <code>1/FPS</code> 间隔内生成的所有点。在此间隔期间，物理不会更新，因此测量中的所有点都反映场景的相同“静态图片”。</p>
<p>此输出包含激光雷达语义检测云，因此，可以对其进行迭代以检索其列表 <a href="../python_api/#carla.SemanticLidarDetection"><code>carla.SemanticLidarDetection</code></a>：</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">detection</span> <span class="ow">in</span> <span class="n">semantic_lidar_measurement</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">detection</span><span class="p">)</span>
</code></pre></div>
<p>可以调整激光雷达的旋转以覆盖每个模拟步骤的特定角度（使用 <a href="../adv_synchrony_timestep/">固定的时间步长</a> ）。例如，每步旋转一次（整圈输出，如下图），旋转频率和模拟的FPS应该相等。 <br>
<strong>1.</strong> 设置传感器的频率 <code>sensors_bp['lidar'][0].set_attribute('rotation_frequency','10')</code>。 <br>
<strong>2.</strong> 使用 <code>python3 config.py --fps=10</code> 运行模拟。</p>
<p><img alt="LidarPointCloud" src="../img/semantic_lidar_point_cloud.jpg" /></p>
<h4 id="_30">语义激光雷达属性</h4>
<p><br></p>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>channels</code></td>
<td>int</td>
<td>32</td>
<td>激光器数量。</td>
</tr>
<tr>
<td><code>range</code></td>
<td>float</td>
<td>10.0</td>
<td>测量/光线投射的最大距离以米为单位（Carla 0.9.6 或更低版本为厘米）。</td>
</tr>
<tr>
<td><code>points_per_second</code></td>
<td>int</td>
<td>56000</td>
<td>所有激光器每秒生成的点。</td>
</tr>
<tr>
<td><code>rotation_frequency</code></td>
<td>float</td>
<td>10.0</td>
<td>激光雷达旋转频率。</td>
</tr>
<tr>
<td><code>upper_fov</code></td>
<td>float</td>
<td>10.0</td>
<td>最高激光的角度（以度为单位）。</td>
</tr>
<tr>
<td><code>lower_fov</code></td>
<td>float</td>
<td>-30.0</td>
<td>最低激光的角度（以度为单位）。</td>
</tr>
<tr>
<td><code>horizontal_fov</code></td>
<td>float</td>
<td>360.0</td>
<td>水平视野（以度为单位），0 - 360。</td>
</tr>
<tr>
<td><code>sensor_tick</code></td>
<td>float</td>
<td>0.0</td>
<td>传感器捕获之间的模拟秒数（节拍）。</td>
</tr>
</tbody>
</table>
<h4 id="_31">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>进行测量时的帧编号。</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>自回合开始以来测量的模拟时间（以秒为单位）。</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>测量时传感器在世界坐标中的位置和旋转。</td>
</tr>
<tr>
<td><code>horizontal_angle</code></td>
<td>float</td>
<td>当前帧中 LIDAR 的 XY 平面中的角度（弧度）。</td>
</tr>
<tr>
<td><code>channels</code></td>
<td>int</td>
<td>LIDAR 的通道（激光器）数量。</td>
</tr>
<tr>
<td><code>get_point_count(channel)</code></td>
<td>int</td>
<td>当前帧中捕获的每个通道的点数。</td>
</tr>
<tr>
<td><code>raw_data</code></td>
<td>bytes</td>
<td>包含具有实例和语义信息的点云的数组。对于每个点，存储四个 32 位浮点数。 <br>  XYZ 坐标。 <br> 入射角的余弦。 <br> Unsigned int 包含命中对象的索引。 <br>  Unsigned int 包含对象 it 的语义标签。</td>
</tr>
</tbody>
</table>
<h2 id="_32">语义分割相机 <span id="semantic-segmentation-camera"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.camera.semantic_segmentation</li>
<li><strong>输出：</strong> 每步 <a href="../python_api/#carla.Image">carla.Image</a> （除非 <code>sensor_tick</code> 另有说明）。</li>
</ul>
<p>该摄像机根据其标签以不同的颜色显示它，从而对可见的每个物体进行分类（例如，行人与车辆的颜色不同）。当模拟开始时，场景中的每个元素都会使用标签创建。所以当参与者产生时就会发生这种情况。对象按其在项目中的相对文件路径进行分类。例如，存储在中的网格<code>Unreal/CarlaUE4/Content/Static/Pedestrians</code>被标记为<code>Pedestrian</code>。</p>
<p><img alt="ImageSemanticSegmentation" src="../img/ref_sensors_semantic.jpg" /></p>
<p>服务器提供的图像的标签信息 <strong>编码在红色通道中</strong>： 红色值为 的像素<code>x</code>属于带有标签的对象<code>x</code>。这个原始的<a href="../python_api/#carla.Image">carla.Image</a>可以在<a href="../python_api/#carla.ColorConverter">carla.ColorConverter</a> 中的 <strong>CityScapesPalette</strong> 的帮助下存储和转换，以应用标签信息并通过语义分割显示图片。</p>
<div class="highlight"><pre><span></span><code><span class="o">...</span>
<span class="n">raw_image</span><span class="o">.</span><span class="n">save_to_disk</span><span class="p">(</span><span class="s2">&quot;path/to/save/converted/image&quot;</span><span class="p">,</span><span class="n">carla</span><span class="o">.</span><span class="n">cityScapesPalette</span><span class="p">)</span>
</code></pre></div>
<p>目前可以使用以下标签（注意：从版本0.9.13到0.9.14数字所对应的标签发生了很大变化）：</p>
<table>
<thead>
<tr>
<th>值</th>
<th>标签</th>
<th>转换后的颜色</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>0</code></td>
<td>Unlabeled</td>
<td><code>(0, 0, 0)</code></td>
<td>考虑尚未分类的元素<code>Unlabeled</code>。该类别应该是空的或至少包含没有冲突的元素。</td>
</tr>
<tr>
<td><code>1</code></td>
<td>Roads</td>
<td><code>(128, 64, 128)</code></td>
<td>汽车通常行驶的部分地面。 <br> 比如，任何方向的车道和街道。</td>
</tr>
<tr>
<td><code>2</code></td>
<td>SideWalk</td>
<td><code>(244, 35, 232)</code></td>
<td>指定供行人或骑自行车者使用的地面的一部分。不仅通过标记，还通过一些障碍物（例如路缘石或杆子）将道路与道路分隔开。该标签包括可能划定的路边、交通岛（步行部分）和步行区。</td>
</tr>
<tr>
<td><code>3</code></td>
<td>Building</td>
<td><code>(70, 70, 70)</code></td>
<td>房屋、摩天大楼等建筑物以及附着在其上的元素。 <br> 例如空调、脚手架、遮阳篷或梯子等。</td>
</tr>
<tr>
<td><code>4</code></td>
<td>Wall</td>
<td><code>(102, 102, 156)</code></td>
<td>独立的立墙。不是建筑物的一部分。</td>
</tr>
<tr>
<td><code>5</code></td>
<td>Fence</td>
<td><code>(100, 40, 40)</code></td>
<td>障碍物、栏杆或其他直立结构。基本上是包围地面区域的木材或电线组件。</td>
</tr>
<tr>
<td><code>6</code></td>
<td>Pole</td>
<td><code>(153, 153, 153)</code></td>
<td>主要为垂直方向的小型杆。如果杆有水平部分（通常用于交通灯杆），则也被视为杆。 <br> 例如标志杆、交通灯杆。</td>
</tr>
<tr>
<td><code>7</code></td>
<td>TrafficLight</td>
<td><code>(250, 170, 30)</code></td>
<td>没有灯杆的交通灯箱。</td>
</tr>
<tr>
<td><code>8</code></td>
<td>TrafficSign</td>
<td><code>(220, 220, 0)</code></td>
<td>由州/市当局安装的标志，通常用于交通管制。此类别不包括附有标志的杆。 <br> 例如交通标志、停车标志、方向标志...</td>
</tr>
<tr>
<td><code>9</code></td>
<td>Vegetation</td>
<td><code>(107, 142, 35)</code></td>
<td>树木、树篱、各种垂直植被。考虑地面植被<code>Terrain</code>。</td>
</tr>
<tr>
<td><code>10</code></td>
<td>Terrain</td>
<td><code>(145, 170, 100)</code></td>
<td>草、地面植被、土壤或沙子。这些区域不适合行驶。该标签包括可能的限制性路缘石。</td>
</tr>
<tr>
<td><code>11</code></td>
<td>Sky</td>
<td><code>(70, 130, 180)</code></td>
<td>开阔的天空。包括云和太阳。</td>
</tr>
<tr>
<td><code>12</code></td>
<td>Pedestrian</td>
<td><code>(220, 20, 60)</code></td>
<td>步行或乘坐/驾驶任何类型的车辆或移动系统的人。 <br> 例如自行车或踏板车、滑板、马、旱冰鞋、轮椅等。</td>
</tr>
<tr>
<td><code>13</code></td>
<td>Rider</td>
<td><code>(0, 0, 142)</code></td>
<td>人类乘坐/驾驶任何类型的车辆或移动系统。<br>  例如：自行车或踏板车、滑板、马、轮滑、轮椅等。</td>
</tr>
<tr>
<td><code>14</code></td>
<td>Car</td>
<td><code>(0, 0, 142)</code></td>
<td>汽车、大蓬货车</td>
</tr>
<tr>
<td><code>15</code></td>
<td>Truck</td>
<td><code>(0, 0, 70)</code></td>
<td>卡车</td>
</tr>
<tr>
<td><code>16</code></td>
<td>Bus</td>
<td><code>(0, 60, 100)</code></td>
<td>公交车</td>
</tr>
<tr>
<td><code>17</code></td>
<td>Truck</td>
<td><code>(0, 80, 100)</code></td>
<td>火车</td>
</tr>
<tr>
<td><code>18</code></td>
<td>Motorcycle</td>
<td><code>(0, 0, 230)</code></td>
<td>摩托车</td>
</tr>
<tr>
<td><code>19</code></td>
<td>Bicycle</td>
<td><code>(119, 11, 32)</code></td>
<td>自行车</td>
</tr>
<tr>
<td><code>20</code></td>
<td>Static</td>
<td><code>(110, 190, 160)</code></td>
<td>场景中的元素和道具是不可移动的。 <br> 例如消防栓、固定长凳、喷泉、公交车站等。</td>
</tr>
<tr>
<td><code>21</code></td>
<td>Dynamic</td>
<td><code>(170, 120, 50)</code></td>
<td>位置容易随时间变化的元素。 <br> 例如可移动垃圾桶、手推车、袋子、轮椅、动物等。</td>
</tr>
<tr>
<td><code>22</code></td>
<td>Other</td>
<td><code>(55, 90, 80)</code></td>
<td>一切不属于任何其他类别的东西。</td>
</tr>
<tr>
<td><code>23</code></td>
<td>Water</td>
<td><code>(45, 60, 150)</code></td>
<td>水平水面。 <br> 例如湖泊、海洋、河流。</td>
</tr>
<tr>
<td><code>24</code></td>
<td>RoadLine</td>
<td><code>(157, 234, 50)</code></td>
<td>道路上的标记。</td>
</tr>
<tr>
<td><code>25</code></td>
<td>Ground</td>
<td><code>(81, 0, 81)</code></td>
<td>与任何其他类别不匹配的任何水平地面结构。例如，车辆和行人共享的区域，或通过路缘与道路分隔的平坦环岛。</td>
</tr>
<tr>
<td><code>26</code></td>
<td>Bridge</td>
<td><code>(150, 100, 100)</code></td>
<td>只有桥的结构。栅栏、人、车辆以及其上的其他元素都被单独标记。</td>
</tr>
<tr>
<td><code>27</code></td>
<td>RailTrack</td>
<td><code>(230, 150, 140)</code></td>
<td>各种非汽车行驶的铁轨。 <br> 例如地铁和火车铁轨。</td>
</tr>
<tr>
<td><code>28</code></td>
<td>GuardRail</td>
<td><code>(180, 165, 180)</code></td>
<td>所有类型的护栏/防撞栏。</td>
</tr>
</tbody>
</table>
<p><br></p>
<div class="admonition 笔记">
<p class="admonition-title">笔记</p>
<p>阅读 <a href="../tuto_D_create_semantic_tags/">本</a> 教程以创建新的语义标签。</p>
</div>
<h4 id="_33">相机基本属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>fov</code></td>
<td>float</td>
<td>90.0</td>
<td>水平视野（以度为单位）。</td>
</tr>
<tr>
<td><code>image_size_x</code></td>
<td>int</td>
<td>800</td>
<td>图像宽度（以像素为单位）。</td>
</tr>
<tr>
<td><code>image_size_y</code></td>
<td>int</td>
<td>600</td>
<td>图像高度（以像素为单位）。</td>
</tr>
<tr>
<td><code>sensor_tick</code></td>
<td>float</td>
<td>0.0</td>
<td>传感器捕获之间的模拟秒数（滴答声）。</td>
</tr>
</tbody>
</table>
<hr />
<h4 id="_34">相机镜头畸变属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>lens_circle_falloff</code></td>
<td>float</td>
<td>5.0</td>
<td>范围： [0.0, 10.0]</td>
</tr>
<tr>
<td><code>lens_circle_multiplier</code></td>
<td>float</td>
<td>0.0</td>
<td>范围： [0.0, 10.0]</td>
</tr>
<tr>
<td><code>lens_k</code></td>
<td>float</td>
<td>-1.0</td>
<td>范围： [-inf, inf]</td>
</tr>
<tr>
<td><code>lens_kcube</code></td>
<td>float</td>
<td>0.0</td>
<td>范围： [-inf, inf]</td>
</tr>
<tr>
<td><code>lens_x_size</code></td>
<td>float</td>
<td>0.08</td>
<td>范围： [0.0, 1.0]</td>
</tr>
<tr>
<td><code>lens_y_size</code></td>
<td>float</td>
<td>0.08</td>
<td>范围： [0.0, 1.0]</td>
</tr>
</tbody>
</table>
<hr />
<h4 id="_35">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>fov</code></td>
<td>float</td>
<td>水平视野（以度为单位）。</td>
</tr>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>进行测量时的帧编号。</td>
</tr>
<tr>
<td><code>height</code></td>
<td>int</td>
<td>图像高度（以像素为单位）。</td>
</tr>
<tr>
<td><code>raw_data</code></td>
<td>bytes</td>
<td>BGRA 32 位像素阵列。</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>自回合开始以来测量的模拟时间（以秒为单位）。</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>测量时传感器在世界坐标中的位置和旋转。</td>
</tr>
<tr>
<td><code>width</code></td>
<td>int</td>
<td>图像宽度（以像素为单位）。</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="_36">实例分割相机 <span id="instance-segmentation-camera"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.camera.instance_segmentation</li>
<li><strong>输出：</strong> 每一步一个 <a href="../python_api/#carla.Image">carla.Image</a> （除非 <code>sensor_tick</code> 另有说明）。</li>
</ul>
<p>该相机根据类别和实例 ID 对视野中的每个对象进行分类。当模拟开始时，场景中的每个元素都会被创建为一个标签。因此，当生成一个参与者时就会发生这种情况。对象根据其在项目中的相对文件路径进行分类。例如，存储在 <code>Unreal/CarlaUE4/Content/Static/Pedestrians</code> 中的网格被标记为行人 <code>Pedestrian</code>。</p>
<p><img alt="ImageInstanceSegmentation" src="../img/instance_segmentation.png" /></p>
<p>服务器提供一张 <strong>在红色通道中编码了</strong> 标签信息的图像：红色值为 <code>x</code> 的像素属于带有标签 <code>x</code> 的对象。像素的绿色和蓝色值定义对象的唯一 ID。例如，8 位 RGB 值为 [10, 20, 55] 的像素是一辆具有唯一实例 ID <code>20-55</code> 的车辆（语义标签为 10）。</p>
<h4 id="_37">基本相机属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>fov</code></td>
<td>float</td>
<td>90.0</td>
<td>水平视野（以度为单位）。</td>
</tr>
<tr>
<td><code>image_size_x</code></td>
<td>int</td>
<td>800</td>
<td>图像宽度（以像素为单位）。</td>
</tr>
<tr>
<td><code>image_size_y</code></td>
<td>int</td>
<td>600</td>
<td>图像高度（以像素为单位）。</td>
</tr>
<tr>
<td><code>sensor_tick</code></td>
<td>float</td>
<td>0.0</td>
<td>传感器捕获之间的模拟秒数（节拍）。</td>
</tr>
</tbody>
</table>
<hr />
<h4 id="_38">相机镜头畸变属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>lens_circle_falloff</code></td>
<td>float</td>
<td>5.0</td>
<td>范围：[0.0, 10.0]</td>
</tr>
<tr>
<td><code>lens_circle_multiplier</code></td>
<td>float</td>
<td>0.0</td>
<td>范围：[0.0, 10.0]</td>
</tr>
<tr>
<td><code>lens_k</code></td>
<td>float</td>
<td>-1.0</td>
<td>范围：[-inf, inf]</td>
</tr>
<tr>
<td><code>lens_kcube</code></td>
<td>float</td>
<td>0.0</td>
<td>范围： [-inf, inf]</td>
</tr>
<tr>
<td><code>lens_x_size</code></td>
<td>float</td>
<td>0.08</td>
<td>范围： [0.0, 1.0]</td>
</tr>
<tr>
<td><code>lens_y_size</code></td>
<td>float</td>
<td>0.08</td>
<td>范围： [0.0, 1.0]</td>
</tr>
</tbody>
</table>
<hr />
<h4 id="_39">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>fov</code></td>
<td>float</td>
<td>水平视野（以度为单位）。</td>
</tr>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>测量发生时的帧号。</td>
</tr>
<tr>
<td><code>height</code></td>
<td>int</td>
<td>图像高度（以像素为单位）。</td>
</tr>
<tr>
<td><code>raw_data</code></td>
<td>bytes</td>
<td>BGRA 32 位像素数组。</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>自情节开始以来的测量模拟时间（以秒为单位）。</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>测量时传感器在世界坐标中的位置和旋转。</td>
</tr>
<tr>
<td><code>width</code></td>
<td>int</td>
<td>图像宽度（以像素为单位）。</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="_40">动态视觉传感器相机 <span id="dvs-camera"></span></h2>
<ul>
<li><strong>蓝图：</strong> sensor.camera.dvs</li>
<li><strong>输出：</strong> 每步 <a href="../python_api/#carla.DVSEventArray">carla.DVSEventArray</a> （除非<code>sensor_tick</code>另有说明）。</li>
</ul>
<p><a href="https://baike.baidu.com/item/%E5%8A%A8%E6%80%81%E8%A7%86%E8%A7%89%E4%BC%A0%E6%84%9F%E5%99%A8/23490201">动态视觉传感器</a> （Dynamic Vision Sensor, DVS）或事件相机是一种工作方式与传统相机完全不同的传感器。事件相机不是以固定速率捕获强度图像，而是以事件流的形式异步测量强度变化，对每个像素的亮度变化进行编码。与标准摄像机相比，事件摄像机具有独特的属性。它们具有非常高的动态范围（140 分贝对 60 分贝（dB, 十分之一 decibel Bell，贝表示的是两个物理量的比值，基准值用分贝表示的话是0dB））、无运动模糊和高时间分辨率（微秒级）。因此，事件相机是即使在具有挑战性的高速场景和高动态范围环境下也能提供高质量视觉信息的传感器，为基于视觉的算法提供了新的应用领域。</p>
<p>动态视觉传感器摄像机输出事件流。当对数强度<code>L</code>的变化达到预定义的恒定阈值（通常在 15% 到 30% 之间）时，在时间戳<code>t</code>处的像素<code>x</code>,<code>y</code>处触发事件<code>e=(x,y,t,pol)</code>。</p>
<p>
<script type="math/tex; mode=display">
L(x,y,t) - L(x,y, t-\delta t) = pol C
</script>
</p>
<p>
<script type="math/tex"> t-\delta t </script> 是该像素上最后一个事件被触发的时间，<code>pol</code>是根据亮度变化的符号来判断事件的极性(polarity)。<code>+1</code>当亮度增加时极性为正，<code>-1</code>当亮度减少时极性为负。工作原理如下图所示。标准相机以固定速率输出帧，从而在场景中不存在运动时发送冗余信息。相比之下，事件摄像机是数据驱动的传感器，能够以微秒延迟响应亮度变化。在绘图中，只要（带符号的）亮度变化随时间<code>t</code>超过一维<code>x</code>的对比度(contrast )阈值<code>C</code>，就会生成正（或负）事件（蓝点、红点） 。观察信号快速变化时事件率如何增长。</p>
<p><img alt="DVSCameraWorkingPrinciple" src="../img/sensor_dvs_scheme.jpg" /></p>
<p>动态视觉传感器的当前实现在两个连续同步帧之间以统一采样方式工作。因此，为了模拟真实事件相机的高时间分辨率（微秒级），传感器需要以高频率执行（比传统相机的频率高得多）。实际上，Carla 汽车行驶速度越快，事件数量就会增加。因此，传感器频率应随着场景的动态而相应增加。用户应该在时间精度和计算成本之间找到平衡。</p>
<p>提供的脚本 <a href="https://github.com/OpenHUTB/carla_doc/blob/master/src/examples/manual_control.py"><code>manual_control.py</code></a> 使用动态视觉传感器摄像头来展示如何配置传感器、如何获取事件流以及如何以图像格式（通常称为事件框架）描述此类事件。</p>
<p>请注意，由于动态视觉传感器摄像机的采样方法，如果两个连续同步帧之间没有像素差异，摄像机将不会返回图像。这总是发生在第一帧中，因为没有前一帧可供比较，并且在帧之间没有移动的情况下也是如此。</p>
<p><img alt="DVSCameraWorkingPrinciple" src="../img/sensor_dvs.gif" /></p>
<p>动态视觉传感器是一个相机，因此具有 RGB 相机中可用的所有属性。然而，事件摄像机的工作原理几乎没有什么独有的属性。</p>
<h4 id="_41">动态视觉传感器相机属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>positive_threshold</code></td>
<td>float</td>
<td>0.3</td>
<td>与亮度变化增量相关的正阈值 C，范围为 (0-1)。</td>
</tr>
<tr>
<td><code>negative_threshold</code></td>
<td>float</td>
<td>0.3</td>
<td>与亮度变化减少相关的负阈值 C，范围为(0-1)。</td>
</tr>
<tr>
<td><code>sigma_positive_threshold</code></td>
<td>float</td>
<td>0</td>
<td>正事件的白噪声标准差，范围为 (0-1)。</td>
</tr>
<tr>
<td><code>sigma_negative_threshold</code></td>
<td>float</td>
<td>0</td>
<td>负事件的白噪声标准差，范围为 (0-1)。</td>
</tr>
<tr>
<td><code>refractory_period_ns</code></td>
<td>int</td>
<td>0.0</td>
<td>不应期（像素在触发事件后无法触发事件的时间），以纳秒为单位。它限制了触发事件的最高频率。</td>
</tr>
<tr>
<td><code>use_log</code></td>
<td>bool</td>
<td>true</td>
<td>是否以对数强度刻度工作。</td>
</tr>
<tr>
<td><code>log_eps</code></td>
<td>float</td>
<td>0.001</td>
<td>用于将图像转换为对数的 Epsilon 值： <code>L = log(eps + I / 255.0)</code>.<br>  其中 <code>I</code> 是 RGB 图像的灰度值： <br><code>I = 0.2989*R + 0.5870*G + 0.1140*B</code>.</td>
</tr>
</tbody>
</table>
<p><br></p>
<hr />
<h2 id="_42">光流相机 <span id="optical-flow-camera"></span></h2>
<p>光流相机捕捉从相机的角度感知的运动。该传感器记录的每个像素都对投影到图像平面的该点的速度进行编码。像素的速度在 [-2,2] 范围内编码。为了获得以像素为单位的运动，可以将该信息与图像大小一起缩放至[-2 * image_size, 2 * image_size]。</p>
<p><img alt="optical_flow" src="../img/optical_flow.png" /></p>
<h4 id="_43">光流相机属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>image_size_x</code></td>
<td>int</td>
<td>800</td>
<td>图像宽度（以像素为单位）。</td>
</tr>
<tr>
<td><code>image_size_y</code></td>
<td>int</td>
<td>600</td>
<td>图像高度（以像素为单位）。</td>
</tr>
<tr>
<td><code>fov</code></td>
<td>float</td>
<td>90.0</td>
<td>水平视野（以度为单位）。</td>
</tr>
<tr>
<td><code>sensor_tick</code></td>
<td>float</td>
<td>0.0</td>
<td>传感器捕获之间的模拟秒数（节拍）。</td>
</tr>
</tbody>
</table>
<h4 id="_44">光流相机镜头畸变属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>lens_circle_falloff</code></td>
<td>float</td>
<td>5.0</td>
<td>范围： [0.0, 10.0]</td>
</tr>
<tr>
<td><code>lens_circle_multiplier</code></td>
<td>float</td>
<td>0.0</td>
<td>范围： [0.0, 10.0]</td>
</tr>
<tr>
<td><code>lens_k</code></td>
<td>float</td>
<td>-1.0</td>
<td>范围： [-inf, inf]</td>
</tr>
<tr>
<td><code>lens_kcube</code></td>
<td>float</td>
<td>0.0</td>
<td>范围： [-inf, inf]</td>
</tr>
<tr>
<td><code>lens_x_size</code></td>
<td>float</td>
<td>0.08</td>
<td>范围： [0.0, 1.0]</td>
</tr>
<tr>
<td><code>lens_y_size</code></td>
<td>float</td>
<td>0.08</td>
<td>范围： [0.0, 1.0]</td>
</tr>
</tbody>
</table>
<h4 id="_45">输出属性</h4>
<table>
<thead>
<tr>
<th>传感器数据属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>进行测量时的帧编号。</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>自回合开始以来测量的模拟时间（以秒为单位）。</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>测量时传感器在世界坐标中的位置和旋转。</td>
</tr>
<tr>
<td><code>width</code></td>
<td>int</td>
<td>图像宽度（以像素为单位）。</td>
</tr>
<tr>
<td><code>height</code></td>
<td>int</td>
<td>图像高度（以像素为单位）。</td>
</tr>
<tr>
<td><code>fov</code></td>
<td>float</td>
<td>水平视野（以度为单位）。</td>
</tr>
<tr>
<td><code>raw_data</code></td>
<td>bytes</td>
<td>包含两个浮点值的 BGRA 64 位像素数组。</td>
</tr>
</tbody>
</table>
<p><br></p>
<hr />
<h2 id="_46"><a href="https://github.com/carla-simulator/carla/pull/3755/files">鱼眼相机</a> <span id="fisheye-camera"></span></h2>
<p><a href="https://zhuanlan.zhihu.com/p/340751380">鱼眼相机镜头</a> 是由十几个不同的透镜组合而成，在成像的过程中，入射光线经过不同程度的折射，投影到尺寸有限的成像平面上，使得鱼眼镜头拥有更大的视野范围。
与针孔相机原理不同，鱼眼镜头采用非相似成像，在成像过程中引入畸变，通过对直径空间的压缩，突破成像视角的局限，从而达到广角成像。
所以鱼眼镜头是一种极端的广角镜头，通常焦距小于等于16mm并且视角接近或等于180°（在工程上视角超过140°的镜头即统称为鱼眼镜头）。进入 <a href="https://pan.baidu.com/s/1n2fJvWff4pbtMe97GOqtvQ?pwd=hutb">网盘</a> 的目录 <code>software/car/fisheye-camera</code> 下载包含鱼眼相机的可执行场景，其实现步骤和原理参考 <a href="../sensor/fisheye_camera/">链接</a> 。</p>
<ul>
<li><strong>蓝图：</strong> sensor.camera.fisheye</li>
<li><strong>输出：</strong> 每一步一个 <a href="../python_api/#carla.ImageCube">carla.ImageCube</a> (除非<code>sensor_tick</code>另有说明)。</li>
</ul>
<p>Fisheye 相机充当常规鱼眼相机，从场景中捕捉图像。
<a href="../python_api/#carla.ColorConverter">carla.colorConverter</a> 定义可用于 carla.ImageCube 的转换模式的类，以显示 <a href="../python_api/#carla.Sensor">carla.Sensor</a> 提供的信息。</p>
<p>这里的 <code>sensor_tick</code> 表示我们希望传感器以多快的速度捕获数据。值为 1.5 表示我们希望传感器每 1.5 秒捕获一次数据。默认情况下，值为 0.0 表示尽可能快。</p>
<p><img alt="FisheyeImage" src="../img/sensor/ref_sensors_fisheye.png" /></p>
<h4 id="_47">基本相机属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>max_angle</code></td>
<td>float</td>
<td>200.0</td>
<td>最大角度（以度为单位）。</td>
</tr>
<tr>
<td><code>x_size</code></td>
<td>float</td>
<td>1000.0</td>
<td>图像宽度（以像素为单位）。</td>
</tr>
<tr>
<td><code>y_size</code></td>
<td>float</td>
<td>900.0</td>
<td>图像高度（以像素为单位）。</td>
</tr>
</tbody>
</table>
<h4 id="_48">相机镜头畸变属性</h4>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>f_x</code></td>
<td>float</td>
<td>300.0</td>
<td>焦距的 x 长度（以像素为单位）。</td>
</tr>
<tr>
<td><code>f_y</code></td>
<td>float</td>
<td>300.0</td>
<td>焦距在的 y 长度（以像素为单位）。</td>
</tr>
<tr>
<td><code>c_x</code></td>
<td>float</td>
<td>600.0</td>
<td>光学中心的 x 坐标（主点），以像素为单位。</td>
</tr>
<tr>
<td><code>c_y</code></td>
<td>float</td>
<td>400.0</td>
<td>光学中心的 y 坐标（主点），以像素为单位。</td>
</tr>
<tr>
<td><code>d_1</code></td>
<td>float</td>
<td>0.0</td>
<td>畸变系数。</td>
</tr>
<tr>
<td><code>d_2</code></td>
<td>float</td>
<td>0.0</td>
<td>畸变系数。</td>
</tr>
<tr>
<td><code>d_3</code></td>
<td>float</td>
<td>0.0</td>
<td>畸变系数。</td>
</tr>
<tr>
<td><code>d_4</code></td>
<td>float</td>
<td>0.0</td>
<td>畸变系数。</td>
</tr>
</tbody>
</table>
<p><br></p>
<hr />
<h2 id="v2x">V2X 传感器 <span id="v2x-sensor"></span></h2>
<p>车联万物 (Vehicle-to-everything, V2X) 通信是未来协作智能交通系统应用的一个重要方面。在实际车辆中，这需要每辆车上都有一个专用的车载单元 (onboard unit, OBU)，能够通过无线信道发送和接收信息。根据地区（欧洲、中国、美国），使用不同的物理技术、协议和应用程序消息格式。</p>
<p>Carla 目前支持模拟简单的广播无线信道和两条应用消息。尚不支持网络访问和转发协议。两条实现的消息分别是符合欧洲标准 ETSI 的 <a href="#cooperative-awareness-message"><em>协作感知消息</em></a> 和 <a href="#custom-v2x-message"><em>自定义消息</em></a> 类型，可用于传输任意字符串数据（例如 JSON）。V2X 通信有两种不同的传感器，可以单独使用，每种应用消息类型各一个。实现原理请参考<a href="../pdf/V2X_sensor.pdf">论文</a> 。</p>
<p>基本上，无线通道包含两个传感器的以下计算：</p>
<pre><code>ReceivedPower = OtherTransmitPower + combined_antenna_gain - loss

IF (ReceivedPower &gt;= receiver_sensitivity)
    THEN message is received
</code></pre>
<p>要模拟 V2X 通信，至少需要生成两个相同类型的 V2X 传感器（至少一对发送器-接收器）。由于接收功率是在接收器端 V2X 传感器上计算的，因此只有接收器端传感器上指定的天线增益才会纳入此计算中。可以配置传输功率和接收器灵敏度（请参阅 <a href="#v2x-sensors-blueprint-attributes">蓝图属性</a> ）。</p>
<p><em>损耗</em> 计算取决于</p>
<ul>
<li>
<p>发送方和接收方之间的可见性条件：视线（无障碍物）、被建筑物遮挡的非视线或被车辆遮挡的非视线，以及 </p>
</li>
<li>
<p>场景：高速公路、乡村或城市环境</p>
</li>
</ul>
<p>虽然在 Carla 中模拟了可见性，但用户可以配置场景（参见 <a href="#v2x-sensors-blueprint-attributes">蓝图属性</a> ），以及无线信道的其他几个属性。</p>
<h3 id="_49">传感器（子）类型</h3>
<h4 id="_50">协同感知消息 <span id="cooperative-awareness-message"></span></h4>
<ul>
<li><strong>蓝图：</strong> sensor.other.v2x</li>
<li><strong>输出：</strong> <a href="../python_api/#carla.CAMData">carla.CAMData</a>, 根据 ETSI CAM (European Telecommunications Standards Institute , Cooperative Awareness Message，欧洲通信标准协会，<a href="https://fanqienovel.com/reader/7110149289141079072">协作感知消息</a> ) 标准触发，除非另有配置</li>
</ul>
<p>根据 ETSI 标准的触发条件：</p>
<ul>
<li>航向角变化 &gt; 4°</li>
<li>位置差 &gt; 4 m</li>
<li>速度变化 &gt; 5 m/s</li>
<li>经过时间 &gt; CAM 生成时间（可配置）</li>
<li>低频容器经过时间 &gt; 500 ms</li>
</ul>
<p>对于 CAM V2X 传感器，使用额外的蓝图属性：</p>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><td colspan=4>    消息生成</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>gen_cam_min</td>
<td>float</td>
<td>0.1</td>
<td>两个连续 CAM 之间的最短时间间隔（秒）</td>
</tr>
<tr>
<td>gen_cam_max</td>
<td>float</td>
<td>1.0</td>
<td>两个连续 CAM 之间的最大时间间隔（秒）</td>
</tr>
<tr>
<td>fixed_rate</td>
<td>bool</td>
<td>false [true]</td>
<td>在每个 Carla 节拍中生成一个 CAM（仅用于调试目的，会导致速度变慢）</td>
</tr>
<tr>
<td><td colspan=4> 数据生成</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>noise_vel_stddev_x</code></td>
<td>float</td>
<td>0.0</td>
<td>噪声模型中速度的标准偏差参数（X 轴）。</td>
</tr>
<tr>
<td><code>noise_accel_stddev_x</code></td>
<td>float</td>
<td>0.0</td>
<td>加速度（X 轴）噪声模型中的标准偏差参数。</td>
</tr>
<tr>
<td><code>noise_accel_stddev_y</code></td>
<td>float</td>
<td>0.0</td>
<td>加速度噪声模型中的标准偏差参数（Y 轴）。</td>
</tr>
<tr>
<td><code>noise_accel_stddev_z</code></td>
<td>float</td>
<td>0.0</td>
<td>加速度（Z 轴）噪声模型中的标准偏差参数。</td>
</tr>
<tr>
<td><code>noise_yawrate_bias</code></td>
<td>float</td>
<td>0.0</td>
<td>噪声模型中偏航角速度的平均参数。</td>
</tr>
<tr>
<td><code>noise_yawrate_stddev</code></td>
<td>float</td>
<td>0.0</td>
<td>偏航角速度噪声模型中的标准偏差参数。</td>
</tr>
<tr>
<td><code>noise_alt_bias</code></td>
<td>float</td>
<td>0.0</td>
<td>噪声模型中海拔的平均参数。</td>
</tr>
<tr>
<td><code>noise_alt_stddev</code></td>
<td>float</td>
<td>0.0</td>
<td>海拔噪声模型中的标准偏差参数。</td>
</tr>
<tr>
<td><code>noise_lat_bias</code></td>
<td>float</td>
<td>0.0</td>
<td>纬度噪声模型中的平均参数。</td>
</tr>
<tr>
<td><code>noise_lat_stddev</code></td>
<td>float</td>
<td>0.0</td>
<td>纬度噪声模型中的标准差参数。</td>
</tr>
<tr>
<td><code>noise_lon_bias</code></td>
<td>float</td>
<td>0.0</td>
<td>噪声模型中经度的平均参数。</td>
</tr>
<tr>
<td><code>noise_lon_stddev</code></td>
<td>float</td>
<td>0.0</td>
<td>噪声模型中经度的标准差参数。</td>
</tr>
<tr>
<td><code>noise_head_bias</code></td>
<td>float</td>
<td>0.0</td>
<td>航向噪声模型中的平均参数。</td>
</tr>
<tr>
<td><code>noise_head_stddev</code></td>
<td>float</td>
<td>0.0</td>
<td>航向噪声模型中的标准偏差参数。</td>
</tr>
</tbody>
</table>
<h4 id="v2x_1">自定义 V2X 消息 <span id="custom-v2x-message"></span></h4>
<ul>
<li><strong>蓝图：</strong> sensor.other.v2x_custom</li>
<li><strong>输出：</strong> <a href="../python_api/#carla.CustomV2XData">carla.CustomV2XData</a>，在调用 <em>send()</em> 后触发下一个滴答信息</li>
</ul>
<h5 id="_51">方法</h5>
<ul>
<li><a name="carla.Sensor.send"></a><strong><font color="#7fb800">send</font></strong>(<font color="#00a6ed"><strong>self</strong></font>, <font color="#00a6ed"><strong>callback</strong></font>)
用户每次发送消息时必须调用的函数。此函数需要一个包含对象类型 <a href="#carla.SensorData">carla.SensorData</a> 的参数来处理。<ul>
<li><strong>参数：</strong><ul>
<li><code>data</code> (<em>function</em>) - 被调用的函数带有一个包含传感器数据的参数。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>自定义 V2X 消息传感器的工作方式与其他传感器略有不同，因为它除了<em>监听</em>函数之外还具有<em>发送</em>函数，需要先调用发送函数，然后其他此类传感器才能接收任何内容。只有在调用<em>发送</em>时才会触发自定义消息的传输。发送给<em>发送</em>函数的每条消息仅向当前生成的所有自定义 V2X 消息传感器传输一次。</p>
<p>示例：</p>
<pre><code>bp = world.get_blueprint_library().find('sensor.other.v2x_custom')
sensor = world.spawn_actor(bp, carla.Transform(), attach_to=parent)
sensor.send("Hello CARLA")
</code></pre>
<h3 id="v2x_2">V2X 传感器蓝图属性</h3>
<table>
<thead>
<tr>
<th>蓝图属性</th>
<th>类型</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>transmit_power</td>
<td>float</td>
<td>21.5</td>
<td>发送方传输功率（单位：dBm）</td>
</tr>
<tr>
<td>receiver_sensitivity</td>
<td>float</td>
<td>-99</td>
<td>接收器灵敏度（单位：dBm）</td>
</tr>
<tr>
<td>frequency_ghz</td>
<td>float</td>
<td>5.9</td>
<td>传输频率（GHz）。5.9 GHz 是多个物理信道的标准。</td>
</tr>
<tr>
<td>noise_seed</td>
<td>int</td>
<td>0</td>
<td>噪声初始化的随机参数</td>
</tr>
<tr>
<td>filter_distance</td>
<td>float</td>
<td>500</td>
<td>最大传输距离（以米为单位），上面的路径损耗计算因模拟速度而略过</td>
</tr>
<tr>
<td><td colspan=4> <strong>路径损耗模型参数</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>combined_antenna_gain</td>
<td>float</td>
<td>10.0</td>
<td>发射机和接收机天线的组合增益（以 dBi 为单位），辐射效率和方向性的参数</td>
</tr>
<tr>
<td>d_ref</td>
<td>float</td>
<td>1.0</td>
<td>对数距离路径损耗模型的参考距离（单位：米）</td>
</tr>
<tr>
<td>path_loss_exponent</td>
<td>float</td>
<td>2.7</td>
<td>由于建筑物遮挡导致的非视距损耗参数</td>
</tr>
<tr>
<td>scenario</td>
<td>string</td>
<td>urban</td>
<td>选项：[urban, rustic, highly available]，定义衰落噪声参数</td>
</tr>
<tr>
<td>path_loss_model</td>
<td>string</td>
<td>geometric</td>
<td>使用的通用路径损耗模型。选项：[geometric, winor]</td>
</tr>
<tr>
<td>use_etsi_fading</td>
<td>bool</td>
<td>true</td>
<td>使用 ETSI 出版物中提到的衰落参数（true），或使用自定义衰落标准偏差</td>
</tr>
<tr>
<td>custom_fading_stddev</td>
<td>float</td>
<td>0.0</td>
<td>衰减标准偏差的自定义值，仅当<code>use_etsi_fading</code>设置为 <code>false</code> 时才使用</td>
</tr>
</tbody>
</table>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/OpenHUTB/carla_doc" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="https://cdn.rawgit.com/knsv/mermaid/6.0.0/dist/mermaid.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.3/underscore-min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/js-sequence-diagrams/1.0.6/sequence-diagram-min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script>
      <script src="../js/umlconvert.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
